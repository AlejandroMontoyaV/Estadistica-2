---
header-includes:
- \usepackage{float}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish, es-tabla]{babel}\decimalpoint
output:
  pdf_document: default
  html_document: default
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: "es"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
library(knitr)
library(kableExtra)
library(tidyverse)
# if(!require(HH)) install.packages("HH"); library(HH)
```

**Estadística II - Taller 02$\hspace{1.6cm}$Semestre: 2023-01**

**Profesores: Francisco Javier Rodríguez Cortés, Julieth Verónica Guarín Escudero**

**Monitor: Matheo Muñoz Betancur**

$\rule{6.5in}{1pt}$

Se presenta una base de datos que recopila información de diferentes clientes de un Ecommerce, a groso modo su tarea consiste en explorar dicha base de datos para ajustar un modelo de regresión adecuado donde la variable respuesta ($Y$) es la cantidad anual gastada por cliente.

```{r chunck, echo=F}
datos <-read.csv("Ecommerce_Customers.csv")

datos[1:5, ] %>% 
  select(Email, Avatar, Yearly.Amount.Spent) %>%
  kable(col.names = c("Email", "Avatar", "Cantidad gastada al año por cliente"),
        align = "c", caption = "Vista previa de la base de datos", booktab = T,
        longtable = T) %>%
  kable_styling(position = "center", latex_options = "hold_position")
```

Su misión como analista es realizar las siguientes tareas usando el software
estadístico **R**.

\begin{enumerate}
\item Realice la lectura de la base de datos, seleccione únicamente las variables numéricas.
\item Elabore un gráfico de dispersión de las variables para encontrar aquella que presente una mejor relación lineal con respecto a la variable respuesta.
\item Escriba la ecuación del modelo de regresión, junto con sus supuestos. Ajuste un modelo de regresión lineal simple y añada la recta de regresión a 
la gráfica generada anteriormente. \textbf{Nota:} seleccione aleatoriamente el 80\%
de los datos para ajustar el modelo.
\item Realice la prueba de significancia para la pendiente, luego realice la prueba de significancia de la regresión usando análisis de varianza. ¿Ambos enfoques permiten llegar a la misma conclusión? ¿Qué relación existe entre una prueba y la otra?
\item Dé una interpretación de los parámetros $\beta_0$ y $\beta_1$ del modelo, en caso  que sea posible hacerlo.
\item Calcule el $R^2$ usando sumas de cuadrados, y realice una interpretación de este.
\item Use el modelo para predecir la cantidad anual total gastada por cliente en el 20\% de los datos que no usó para ajustar el modelo. Calcule los respectivos intervalos de confianza y de predicción. ¿Cuáles intervalos son más anchos? ¿Por qué cree usted que esto sucede?
\end{enumerate}

\section*{Solución}

\subsection*{Ejercicio 1}

Primero, se realiza la lectura de la base de datos con

```{r}
datos <- read.csv("Ecommerce_Customers.csv")
```

Para seleccionar las variables numéricas, se observa primero la estructura de la variable datos, así:

```{r}
str(datos)
```
Se puede observar que hay 5 variables númericas, así, se hace la selección de estas.

```{r}
datos.filtrados <- datos %>% 
  select(Avg..Session.Length:Length.of.Membership, Yearly.Amount.Spent)
```

Note que la variable *Yearly.Amount.Spent* será la variable respuesta $Y$.

\subsubsection*{Ejercicio 2}

El gráfico de dispersión que relacion todas las variables entre sí para observar entre cuáles puede existir linealidad basta con hacer lo siguiente a estos datos:

```{r}
plot(datos.filtrados, pch=20)
```

Así, es claro  que la covariable $X$ que mejor relación lineal presenta con la variable cantidad anual gastada por cliente, la cual es la variable respuesta $Y$ es la duración de su membresía (*Length.of.Membership*). Por esto, se crea la nueva variable en **R** con los datos a utilizar:

```{r}
datos.modelo <- datos.filtrados %>% 
  select(Yearly.Amount.Spent, Length.of.Membership)
```

El número de datos para el ajuste son 80\% del número de datos.

```{r}
n <- 0.8 * nrow(datos.modelo)
n
```

\subsection*{Ejercicio 3}

Considerando la duración de la membresía como la covariable $X$ y la cantidad anual gastada como la respuesta $Y$, se plantea el siguiente modelo de regresión:

\begin{equation*}
  Y_i = \beta_0 + \beta_1X_i,\  \varepsilon_i \stackrel{\text{iid}}{\sim} \mathcal{N}(0, \sigma^2)
\end{equation*}

Donde $1 \leq i \leq n$ con $n=400$. Seleccionando aleatoriamente 400 datos de la variable datos.modelo y ajustando el modelo de regresión:

```{r}
n <- 500 #Para recuperar el valor total de n
set.seed(9012913) #Para permitir reproducibilidad de la aleatoriedad
filas <- sample(1:n, 0.8*n)
datos.ajuste <- datos.modelo[filas, ]
datos.prediccion <- datos.modelo[-filas,  ]
mod <- lm(Yearly.Amount.Spent ~ Length.of.Membership, data=datos.ajuste)
summary(mod)
```

Aquí se puede observar que:

\begin{itemize}
  \item $\hat{\beta_0} = 266.684$, cuyo error estándar es $8.802$, su estadístico de prueba para significancia individual es $T=30.30$ y su valor-P es del orden de 0.
  \item $\hat{\beta_1} = 66.393$, cuyo error estándar es $2.398$, su estadístico de prueba para significancia individual es $T=27.69$ y su valor-P es del orden de 0.
\end{itemize}

Ahora, se presenta la gráfica de $Y$ vs $X$ con el ajuste:

```{r}
p <- ggplot(datos.ajuste, aes(x=Length.of.Membership, y= Yearly.Amount.Spent)) + geom_point() + geom_smooth(col="red", formula="y~x", method = "lm", se=F) + labs(x="Duración de membresía(mes)", y="Cantidad anual gastada por cliente")
p
```

\subsection*{Ejercicio 4}

En el ejercicio anterior se presentó el valor-P para la prueba de significancia de la pendiente que plantea

$$
\begin{cases}
  H_0: \beta_1 = 0 \\
  H_1: \beta_1 \neq 0
\end{cases}
$$

El cual arrojó un valor cercano a 0, mucho menor a cualquier valor de significancia, por lo que se rechaza la hipótesis nula y la pendiente es significativa. Para usar análisis de varianza para la prueba de significancia de la regresión, se presenta a continuación la tabla anova:

```{r}
anova(mod)
```

De aquí es posible afirmar que la regresión es significativa, lo cual no contradice el resultado dado por la hipótesis individual. También, cuando se usa análisis de varianza en un modelo lineal con sólo un parámetro que hace significativa la regresión, el estadístico $T$ y $F$ de las pruebas están relacionados pues $F_0 = T_0 ^2$, esto se puede ver en R

```{r}
F.subcero <- 766.79
T.subcero <- 27.69
T.subcero^2
```
\subsection*{Ejercicio 5}

\begin{itemize}
  \item $\hat{\beta_0}$: Como el valor de $X=0$ no hace parte de los datos, entonces no es interpretable
  \item $\hat{\beta_1}$: Cuando una persona aumenta su tiempo de suscripción en un mes, se  estima que su gasto anual medio incrementa $66.393$USD
\end{itemize}

\subsection*{Ejercicio 6}

Tomando en cuenta los valores que pueden ser extraídos de la tabla anova para la suma cuadrática de regresión y la suma cuadrática de error, se tiene:

\begin{equation*}
  R^2 = \frac{\text{SSR}}{\text{SST}} = \frac{\text{SSR}}{\text{SSR} + \text{SSE}} = \frac{1663089}{1663089 + 863224} = 0.6583068
\end{equation*}

El $R^2$ es la proporción de la variabilidad de la respuesta explicada por la regresión. Un $R^2 = 0.6583068$ significa que la regresión explica aproximadamente 65.83\% de la variabilidad de la respuesta.

\subsection*{Ejercicio 7}

El  intervalo de confianza para una observación futura es más ancho, lo cual puede ser observado en su fórmula y esto es debido a que su predicción se hace considerando un error de predicción, el cual al hallar su varianza hace que se infle su valor respecto al valor de la respuesta media. Una función en **R** que permite obtener el intervalo de confianza para la respuesta media es la que sigue(**Nota:** para hacer esta inferencia, es necesario hacer uso sólo de los datos que se utilizaron en la regresión):

```{r}
int.conf.media <- predict(mod, newdata = datos.ajuste, interval = "confidence", level = 0.95)

int.conf.media[1:5, ] #5 primeras entradas de la tabla
```

Para los intervalos de predicción similarmente en **R**:

```{r}
int.conf.futuro <- predict(mod, newdata = datos.prediccion, interval = "prediction", level = 0.95)

int.conf.futuro[1:5, ] #5 primeras entradas de la tabla
```

Note acá que los datos para predicción no pueden ser datos usados en la predicción y deben estar entre el mínimo y máximo de los datos de la misma, es decir, deben ser de interpolación.
